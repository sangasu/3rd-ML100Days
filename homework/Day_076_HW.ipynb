{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業重點:\n",
    "\n",
    "(1)以, Adam, 為例, 調整 batch_size, epoch , 觀察accurancy, loss 的變化\n",
    "\n",
    "(2)以同一模型, 分別驗證 SGD, Adam, Rmsprop 的 accurancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業目標:\n",
    "    \n",
    "    取得各種優化器的運算結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'GPUOptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-6cc6affb4294>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Blas GEMM launch failed , 避免動態分配GPU / CPU, 出現問題\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgpu_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGPUOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mper_process_gpu_memory_fraction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.333\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'GPUOptions'"
     ]
    }
   ],
   "source": [
    "#Blas GEMM launch failed , 避免動態分配GPU / CPU, 出現問題\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "   宣告並設定\n",
    "   batch_size：對總的樣本數進行分組，每組包含的樣本數量\n",
    "   epochs ：訓練次數\n",
    "   \n",
    "''' \n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 30\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    第一步：選擇模型, 順序模型是多個網絡層的線性堆疊\n",
    " \n",
    "model = Sequential()\n",
    "\n",
    "#   第二步：構建網絡層\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense( 10)) # 輸出結果是10個類別，所以維度是10   \n",
    "model.add(Activation('softmax')) # 最後一層用softmax作為激活函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters：1250858\n"
     ]
    }
   ],
   "source": [
    "# 模型建立完成後，統計參數總量\n",
    "print(\"Total Parameters：%d\" % model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 輸出模型摘要資訊\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第三步編譯\n",
    "'''\n",
    " SGD(隨機梯度下降) - Arguments\n",
    "lr: float >= 0. Learning rate.\n",
    "momentum: float >= 0. Parameter that accelerates SGD in the relevant direction and dampens oscillations.\n",
    "decay: float >= 0. Learning rate decay over each update.\n",
    "nesterov: boolean. Whether to apply Nesterov momentum.\n",
    "'''\n",
    "#opt=optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#Test loss: 0.6192809438228607\n",
    "#Test accuracy: 0.8001999855041504\n",
    "'''\n",
    "RMSprop- Arguments\n",
    "lr: float >= 0. Learning rate.\n",
    "rho: float >= 0.\n",
    "epsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\n",
    "decay: float >= 0. Learning rate decay over each update.\n",
    "'''\n",
    "#opt=keras.optimizers.RMSprop(lr=0.001, rho=0.9, decay=0.0)\n",
    "#Test loss: 1.070328008556366\n",
    "#Test accuracy: 0.6644999980926514\n",
    "\n",
    "opt=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.0, amsgrad=False)\n",
    "#Test loss: 0.6256539429664612\n",
    "#Test accuracy: 0.801800012588501\n",
    "'''\n",
    "Example:\n",
    "opt = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "'''\n",
    "\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料正規化\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.0312 - accuracy: 0.6707 - val_loss: 0.8483 - val_accuracy: 0.7163\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.9198 - accuracy: 0.7030 - val_loss: 0.7811 - val_accuracy: 0.7436\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.8706 - accuracy: 0.7139 - val_loss: 0.7682 - val_accuracy: 0.7587\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.8553 - accuracy: 0.7228 - val_loss: 0.8138 - val_accuracy: 0.7388\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.8276 - accuracy: 0.7304 - val_loss: 0.7715 - val_accuracy: 0.7481\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.7972 - accuracy: 0.7408 - val_loss: 0.7591 - val_accuracy: 0.7590\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.7896 - accuracy: 0.7419 - val_loss: 0.7645 - val_accuracy: 0.7505\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 0.7485 - accuracy: 0.7554 - val_loss: 0.7143 - val_accuracy: 0.7745\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 11s 229us/step - loss: 0.7450 - accuracy: 0.7563 - val_loss: 0.7171 - val_accuracy: 0.7697\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.7186 - accuracy: 0.7644 - val_loss: 0.7275 - val_accuracy: 0.7644\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.7189 - accuracy: 0.7649 - val_loss: 0.7550 - val_accuracy: 0.7736\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.7071 - accuracy: 0.7673 - val_loss: 0.7354 - val_accuracy: 0.7843\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.6879 - accuracy: 0.7732 - val_loss: 0.7219 - val_accuracy: 0.7567\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.6689 - accuracy: 0.7781 - val_loss: 0.7060 - val_accuracy: 0.7756\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 0.6618 - accuracy: 0.7786 - val_loss: 0.6871 - val_accuracy: 0.7857\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 0.6641 - accuracy: 0.7816 - val_loss: 0.6539 - val_accuracy: 0.7884\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.6528 - accuracy: 0.7830 - val_loss: 0.6745 - val_accuracy: 0.7905\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.6473 - accuracy: 0.7857 - val_loss: 0.6681 - val_accuracy: 0.7908\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 0.6373 - accuracy: 0.7907 - val_loss: 0.6241 - val_accuracy: 0.7951\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.6175 - accuracy: 0.7960 - val_loss: 0.6608 - val_accuracy: 0.7927\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.6172 - accuracy: 0.7959 - val_loss: 0.6527 - val_accuracy: 0.7909\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.6055 - accuracy: 0.8001 - val_loss: 0.6261 - val_accuracy: 0.7938\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.6029 - accuracy: 0.7980 - val_loss: 0.6609 - val_accuracy: 0.7966\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.6039 - accuracy: 0.7981 - val_loss: 0.6370 - val_accuracy: 0.7990\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 0.5943 - accuracy: 0.8002 - val_loss: 0.7181 - val_accuracy: 0.7954\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.5906 - accuracy: 0.8010 - val_loss: 0.6510 - val_accuracy: 0.7941\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.5894 - accuracy: 0.8017 - val_loss: 0.6274 - val_accuracy: 0.7997\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.5709 - accuracy: 0.8078 - val_loss: 0.6899 - val_accuracy: 0.7904\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.5771 - accuracy: 0.8063 - val_loss: 0.6796 - val_accuracy: 0.7979\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.5705 - accuracy: 0.8085 - val_loss: 0.6257 - val_accuracy: 0.8018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n   第四步：訓練\\n   .fit的一些參數\\n   batch_size：對總的樣本數進行分組，每組包含的樣本數量\\n   epochs ：訓練次數\\n   shuffle：是否把數據隨機打亂之後再進行訓練\\n   validation_split：拿出百分之多少用來做交叉驗證\\n   verbose：屏顯模式 - 0：不輸出, 1：輸出進度, 2：輸出每次的訓練結果\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 是否要做資料處理\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    history=model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    print('')\n",
    "        \n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "    history=model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)   \n",
    "\n",
    "'''\n",
    "   第四步：訓練\n",
    "   .fit的一些參數\n",
    "   batch_size：對總的樣本數進行分組，每組包含的樣本數量\n",
    "   epochs ：訓練次數\n",
    "   shuffle：是否把數據隨機打亂之後再進行訓練\n",
    "   validation_split：拿出百分之多少用來做交叉驗證\n",
    "   verbose：屏顯模式 - 0：不輸出, 1：輸出進度, 2：輸出每次的訓練結果\n",
    "''' \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:\\Users\\Sanga\\repos\\3rd-ML100Days\\saved_models\\keras_cifar10_trained_model.h5 \n",
      "10000/10000 [==============================] - 1s 121us/step\n",
      "Test loss: 0.6256539429664612\n",
      "Test accuracy: 0.801800012588501\n"
     ]
    }
   ],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    第六步：輸出\n",
    "import numpy \n",
    "\n",
    "print ( \" test set \" )\n",
    "scores = model.evaluate(x_test,y_test,batch_size=200,verbose= 0)\n",
    "print ( \"\" )\n",
    "#print ( \" The test loss is %f \" % scores)\n",
    "print ( \" The test loss is %f \", scores)\n",
    "\n",
    "\n",
    "result = model.predict(x_test,batch_size=200,verbose= 0)\n",
    "\n",
    "result_max = numpy.argmax(result, axis = 1 )\n",
    "test_max = numpy.argmax(y_test, axis = 1 )\n",
    "\n",
    "result_bool = numpy.equal(result_max, test_max)\n",
    "true_num = numpy.sum(result_bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valiidation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valiidation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
